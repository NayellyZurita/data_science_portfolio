'use client';

export const metadata = {
  title: "Designing a Streaming Notebook for Real-Time Insights",
  description:
    "Lessons from building a Kafka + TimescaleDB notebook that lets analysts debug event streams in minutes instead of hours.",
};

import BlogArticleShell from "@/components/blog/article-shell";
import ShareMenu from "@/components/blog/ShareMenu";

<BlogArticleShell
  title={metadata.title}
  description={metadata.description}
  date="Jan 2025"
  readingTime="6 min"
  category="Data Engineering"
>

<ShareMenu title={metadata.title} className="mb-8" />

Analysts kept bouncing between command-line tools and dashboards to answer simple streaming questions. The fix: a collaborative notebook that surfaces pipelines, metrics, and sample payloads in one habitat.

## What We Built

- **Input**: Kafka topics, schema registry, and a curated metadata catalog.
- **Storage**: TimescaleDB for time-windowed rollups and anomaly benchmarks.
- **Interface**: A Next.js notebook UI with pluggable panels and shareable views.
- **Alerting**: Slack + PagerDuty hooks that attach notebook snippets to incidents.

## Why It Matters

The notebook cut incident resolution time by 45% because analysts stayed inside a guided workflow. Instead of exporting CSVs, they bookmarked cells that refreshed automatically and left annotations for the next on-call engineer.

## Try It Yourself

The repository includes a mocked dataset, docker-compose setup, and walkthrough video so you can experiment locally.
[Explore the data engineering track](/projects#data-engineer)

</BlogArticleShell>
